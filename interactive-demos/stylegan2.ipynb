{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn4nwGUcEM7J"
      },
      "source": [
        "# StyleGAN2\n",
        "\n",
        "![styleGAN2 generated image sample](https://github.com/sony/nnabla-examples/raw/master/image-generation/stylegan2/images/sample.png)\n",
        "\n",
        "This example demonstrates face image generation using [StyleGAN2](https://github.com/NVlabs/stylegan2). StyleGAN2 is one of the generative models which can generate high-resolution images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cRszVNjEM7N"
      },
      "source": [
        "# Preparation\n",
        "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime → change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sj-0VrLDEM7N",
        "outputId": "0b4cdc8a-0f98-45b7-ca9a-f82b0175bf20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnabla-ext-cuda100\n",
            "  Downloading nnabla_ext_cuda100-1.25.0-cp37-cp37m-manylinux_2_17_x86_64.whl (51.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.1 MB 190 kB/s \n",
            "\u001b[?25hCollecting nnabla==1.25.0\n",
            "  Downloading nnabla-1.25.0-cp37-cp37m-manylinux_2_17_x86_64.whl (18.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.1 MB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nnabla-ext-cuda100) (57.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (4.64.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (0.5.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.6 in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (3.17.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (0.29.28)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (1.4.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.44-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<=3.1.0 in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (1.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (2.4.1)\n",
            "Collecting configparser\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from nnabla==1.25.0->nnabla-ext-cuda100) (7.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py<=3.1.0->nnabla==1.25.0->nnabla-ext-cuda100) (1.5.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.44\n",
            "  Downloading botocore-1.24.44-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 18.8 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.44->boto3->nnabla==1.25.0->nnabla-ext-cuda100) (2.8.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, configparser, boto3, nnabla, nnabla-ext-cuda100\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.44 botocore-1.24.44 configparser-5.2.0 jmespath-1.0.0 nnabla-1.25.0 nnabla-ext-cuda100-1.25.0 s3transfer-0.5.2 urllib3-1.26.9\n",
            "Cloning into 'nnabla-examples'...\n",
            "remote: Enumerating objects: 7394, done.\u001b[K\n",
            "remote: Counting objects: 100% (470/470), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 7394 (delta 396), reused 346 (delta 346), pack-reused 6924\u001b[K\n",
            "Receiving objects: 100% (7394/7394), 290.69 MiB | 33.62 MiB/s, done.\n",
            "Resolving deltas: 100% (4100/4100), done.\n",
            "Checking out files: 100% (1459/1459), done.\n",
            "/content/nnabla-examples/image-generation/stylegan2\n"
          ]
        }
      ],
      "source": [
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%cd nnabla-examples/image-generation/stylegan2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEfm_uumEM7O"
      },
      "source": [
        "# Get the pretrained weights\n",
        "Now we will get the pretrained weights for styleGAN2, then import some modules and do some preparation for the latter part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fQRu4xttEM7P",
        "outputId": "e415be89-8529-4dba-9cb6-2b4b0fcb814f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 12:21:13--  https://nnabla.org/pretrained-models/nnabla-examples/GANs/stylegan2/styleGAN2_G_params.h5\n",
            "Resolving nnabla.org (nnabla.org)... 18.160.200.9, 18.160.200.40, 18.160.200.38, ...\n",
            "Connecting to nnabla.org (nnabla.org)|18.160.200.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121643776 (116M) [binary/octet-stream]\n",
            "Saving to: ‘styleGAN2_G_params.h5’\n",
            "\n",
            "styleGAN2_G_params. 100%[===================>] 116.01M  34.0MB/s    in 3.4s    \n",
            "\n",
            "2022-04-21 12:21:17 (34.0 MB/s) - ‘styleGAN2_G_params.h5’ saved [121643776/121643776]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-21 12:21:17,389 [nnabla][INFO]: Initializing CPU extension...\n",
            "2022-04-21 12:21:19,012 [nnabla][INFO]: Initializing CUDA extension...\n",
            "2022-04-21 12:21:19,122 [nnabla][INFO]: Initializing cuDNN extension...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!wget https://nnabla.org/pretrained-models/nnabla-examples/GANs/stylegan2/styleGAN2_G_params.h5\n",
        "from generate import *\n",
        "from IPython.display import Image, display\n",
        "ctx = get_extension_context(\"cudnn\")\n",
        "nn.set_default_context(ctx)\n",
        "\n",
        "num_layers = 18\n",
        "output_dir = 'results'\n",
        "\n",
        "nn.load_parameters(\"styleGAN2_G_params.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ_edMjJEM7P"
      },
      "source": [
        "# StyleGAN2 input config\n",
        "\n",
        "In styleGAN2, the noise input **z** is fed to the **mapping network** to produce the latent code **w**. Then **w** is modified via **truncation trick** and finally the modified latent code **w'** is injected to the **synthesis network**.\n",
        "\n",
        "With multiple latent codes **w'** coming from the **mapping network**, **synthesis network** transforms the incoming tensor and gradually converts it to an image. \n",
        "\n",
        "This is how styleGAN2 generates photo-realistic high resolution images. \n",
        "\n",
        "In the following cell,  you will choose the random seed used for sampling the noise input **z**, the value for **truncation trick**, and another random seed used for the additional noise input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w1TF6kLLEM7Q"
      },
      "outputs": [],
      "source": [
        "#@markdown Choose the seed for noise input **z**. (This drastically changes the result)\n",
        "latent_seed = 524  #@param {type: \"slider\", min: 0, max: 1000, step:1}\n",
        "\n",
        "#@markdown Choose the value for truncation trick.\n",
        "truncation_psi = 0.5  #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.01}\n",
        "\n",
        "#@markdown Choose the seed for stochasticity input.  (This slightly changes the result)\n",
        "noise_seed = 500  #@param {type: \"slider\", min: 0, max: 1000, step:1}\n",
        "\n",
        "#@markdown Number of images to generate\n",
        "batch_size = 1  #@param {type: \"slider\", min: 0, max: 20, step:1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_z3oXgGMfuY"
      },
      "source": [
        "# Now let's run StyleGAN2!\n",
        "Execution the following cell will run the styleGAN2. You can see by changing the value used for **truncation trick**, you will get the different results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OycXlFf0EM7R"
      },
      "outputs": [],
      "source": [
        "rnd = np.random.RandomState(latent_seed)\n",
        "z = rnd.randn(batch_size, 512)\n",
        "\n",
        "nn.set_auto_forward(True) \n",
        "\n",
        "style_noise = nn.NdArray.from_numpy_array(z)\n",
        "style_noises = [style_noise for _ in range(2)] \n",
        "\n",
        "rgb_output = generate(batch_size, style_noises, noise_seed, mix_after=7, truncation_psi=truncation_psi) \n",
        "\n",
        "images = convert_images_to_uint8(rgb_output, drange=[-1, 1])\n",
        "\n",
        "# Display all the images\n",
        "for i in range(batch_size):\n",
        "  filename = f'seed{latent_seed}_{i}.png'\n",
        "  imsave(filename, images[i], channel_first=True)\n",
        "  display(Image(filename, width=512, height=512))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1-5zSiUEM7S"
      },
      "source": [
        "# Try Style Mixing\n",
        "\n",
        "![styleGAN2 generated image sample](https://github.com/sony/nnabla-examples/raw/master/image-generation/stylegan2/images/style_mixing_sample.png)\n",
        "\n",
        "As described above, in styleGAN2, **synthesis network** receives latent code **w** multiple times and generates images. In the previous generation, latent code **w** which **synthesis network** receives is made from one single noise input **z**. In this case, we can say that **w** controls the *style* of the generated image.\n",
        "\n",
        "Given that, with a *different* latent code **w2**, made from another noise input **z2**, **synthesis network** can generate a completely different image. So, what if we use both **w** and **w2**...? That is, *style mixing*.\n",
        "\n",
        "To be specific, using 2 latent codes **w** and **w2**, **synthesis network** can generate the image which contains both elements (i.e. hair style, face components), present in images made from **w** (controling coarse style) and **w2** (controling fine style).\n",
        "\n",
        "In the following cell, you will choose one more random seed used for sampling another noise input **z2**. \n",
        "\n",
        "You can also choose from which layer it receives the additional latent code **w2**. It slightly changes the result, so try various patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-kbiTzKlEM7S"
      },
      "outputs": [],
      "source": [
        "#@title StyleGAN2 style mixing config\n",
        "#@markdown Choose seed for the primary noise input **z**. This will represent coarse style.\n",
        "latent_seed = 600  #@param {type: \"slider\", min: 0, max: 1000, step:1}\n",
        "\n",
        "#@markdown Choose seed for the secondary noise input **z2**. This will represent fine style.\n",
        "latent_seed2 = 500  #@param {type: \"slider\", min: 0, max: 1000, step:1}\n",
        "\n",
        "#@markdown Choose from which layer to use the secondary latent code **w2**.\n",
        "mix_after = 7  #@param {type: \"slider\", min: 0, max: 17, step:1}\n",
        "\n",
        "#@markdown Choose seed for stochasticity input.\n",
        "noise_seed = 500  #@param {type: \"slider\", min: 0, max: 1000, step:1}\n",
        "\n",
        "#@markdown Choose the value for truncation trick.\n",
        "truncation_psi = 0.5  #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.01}\n",
        "\n",
        "#@markdown Number of images made solely from coarse style noise\n",
        "batch_size_A = 1  #@param {type: \"slider\", min: 0, max: 20, step:1}\n",
        "\n",
        "#@markdown Number of images made solely from fine style noise\n",
        "batch_size_B = 4  #@param {type: \"slider\", min: 0, max: 20, step:1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbrhoXDuEM7T"
      },
      "source": [
        "# Let's run style mixing.\n",
        "\n",
        "Running this cell executes style mixing and displays a generated mixed image and images made solely from **w** / **w2**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnb4lP44EM7T"
      },
      "outputs": [],
      "source": [
        "rnd1 = np.random.RandomState(latent_seed)\n",
        "z1 = nn.NdArray.from_numpy_array(rnd1.randn(batch_size_A, 512))\n",
        "\n",
        "rnd2 = np.random.RandomState(latent_seed2)\n",
        "z2 = nn.NdArray.from_numpy_array(rnd2.randn(batch_size_B, 512))\n",
        "\n",
        "nn.set_auto_forward(True)\n",
        "\n",
        "mix_image_stacks = []\n",
        "for i in range(batch_size_A):\n",
        "  image_column = []\n",
        "  for j in range(batch_size_B):\n",
        "    style_noises = [F.reshape(z1[i], (1, 512)), F.reshape(z2[j], (1, 512))]\n",
        "    rgb_output = generate(1, style_noises, noise_seed, mix_after, truncation_psi)\n",
        "    image_column.append(convert_images_to_uint8(rgb_output, drange=[-1, 1])[0])\n",
        "  image_column = np.concatenate([image for image in image_column], axis=2)\n",
        "  mix_image_stacks.append(image_column)\n",
        "mix_image_stacks = np.concatenate([image for image in mix_image_stacks], axis=1)\n",
        "\n",
        "style_noises= [z1, z1]\n",
        "rgb_output = generate(batch_size_A, style_noises, noise_seed, mix_after, truncation_psi)\n",
        "image_A = convert_images_to_uint8(rgb_output, drange=[-1, 1])\n",
        "image_A = np.concatenate([image for image in image_A], axis=1)\n",
        "\n",
        "style_noises = [z2, z2]\n",
        "rgb_output = generate(batch_size_B, style_noises, noise_seed, mix_after, truncation_psi)\n",
        "image_B = convert_images_to_uint8(rgb_output, drange=[-1, 1])\n",
        "image_B = np.concatenate([image for image in image_B], axis=2)\n",
        "\n",
        "top_image = 255 * np.ones(rgb_output[0].shape).astype(np.uint8)\n",
        "\n",
        "top_image = np.concatenate((top_image, image_B), axis=2)\n",
        "grid_image = np.concatenate((image_A, mix_image_stacks), axis=2)\n",
        "grid_image = np.concatenate((top_image, grid_image), axis=1)\n",
        "\n",
        "imsave(\"grid.png\", grid_image, channel_first=True)\n",
        "display(Image(\"grid.png\", width=256*(batch_size_B+1), height=256*(batch_size_A+1)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "stylegan2.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}