{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled97.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMaHXujfL3jED15LhggeceO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c075f22993b94453a0b208c5205f18f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d154cda7f9d3478bad3d9853eb35a1c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_388619fa55bd4369bbdea796d2cff352",
              "IPY_MODEL_601bf58ba5ad430aac5ec512e12372cc",
              "IPY_MODEL_8d1114af37714bc1897a9d780c961a43"
            ]
          }
        },
        "d154cda7f9d3478bad3d9853eb35a1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "388619fa55bd4369bbdea796d2cff352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d509fd3b1524bda987d276ff498f99d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeacccfa65ad48db922b10b99c40d150"
          }
        },
        "601bf58ba5ad430aac5ec512e12372cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acc8a6dfa1454c81873b67f8ffe38169",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_739d1bdfc7454d4ebfe3f08f97b6ab43"
          }
        },
        "8d1114af37714bc1897a9d780c961a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17a92cd98ad443948e9929daf10a9098",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 73356745.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd54cd3a67394d90983c2bb5cd8b630d"
          }
        },
        "3d509fd3b1524bda987d276ff498f99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeacccfa65ad48db922b10b99c40d150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acc8a6dfa1454c81873b67f8ffe38169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "739d1bdfc7454d4ebfe3f08f97b6ab43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17a92cd98ad443948e9929daf10a9098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd54cd3a67394d90983c2bb5cd8b630d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Colab_Scripts/blob/master/FixMatch_pytorh_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**FixMatch-pytorch for Colab**\n",
        "This is an unofficial implementation of FixMatch-pytoch for Colab, based on https://github.com/kekmodel/FixMatch-pytorch.\n"
      ],
      "metadata": {
        "id": "n5cGRM7-llul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EtVI0tQ-C9gy"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.ImageDraw\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "best_acc = 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Define RandAugument**"
      ],
      "metadata": {
        "id": "Q6vcOrsfg4_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAMETER_MAX = 10\n",
        "\n",
        "\n",
        "def AutoContrast(img, **kwarg):\n",
        "    return PIL.ImageOps.autocontrast(img)\n",
        "\n",
        "\n",
        "def Brightness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
        "\n",
        "\n",
        "def Color(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
        "\n",
        "\n",
        "def Contrast(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
        "\n",
        "\n",
        "def Cutout(img, v, max_v, bias=0):\n",
        "    if v == 0:\n",
        "        return img\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    v = int(v * min(img.size))\n",
        "    return CutoutAbs(img, v)\n",
        "\n",
        "\n",
        "def CutoutAbs(img, v, **kwarg):\n",
        "    w, h = img.size\n",
        "    x0 = np.random.uniform(0, w)\n",
        "    y0 = np.random.uniform(0, h)\n",
        "    x0 = int(max(0, x0 - v / 2.))\n",
        "    y0 = int(max(0, y0 - v / 2.))\n",
        "    x1 = int(min(w, x0 + v))\n",
        "    y1 = int(min(h, y0 + v))\n",
        "    xy = (x0, y0, x1, y1)\n",
        "    # gray\n",
        "    color = (127, 127, 127)\n",
        "    img = img.copy()\n",
        "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
        "    return img\n",
        "\n",
        "\n",
        "def Equalize(img, **kwarg):\n",
        "    return PIL.ImageOps.equalize(img)\n",
        "\n",
        "\n",
        "def Identity(img, **kwarg):\n",
        "    return img\n",
        "\n",
        "\n",
        "def Invert(img, **kwarg):\n",
        "    return PIL.ImageOps.invert(img)\n",
        "\n",
        "\n",
        "def Posterize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.posterize(img, v)\n",
        "\n",
        "\n",
        "def Rotate(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "\n",
        "def Sharpness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
        "\n",
        "\n",
        "def ShearX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "\n",
        "\n",
        "def ShearY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
        "\n",
        "\n",
        "def Solarize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.solarize(img, 256 - v)\n",
        "\n",
        "\n",
        "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    img_np = np.array(img).astype(np.int)\n",
        "    img_np = img_np + v\n",
        "    img_np = np.clip(img_np, 0, 255)\n",
        "    img_np = img_np.astype(np.uint8)\n",
        "    img = Image.fromarray(img_np)\n",
        "    return PIL.ImageOps.solarize(img, threshold)\n",
        "\n",
        "\n",
        "def TranslateX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[0])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[1])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "\n",
        "def _float_parameter(v, max_v):\n",
        "    return float(v) * max_v / PARAMETER_MAX\n",
        "\n",
        "\n",
        "def _int_parameter(v, max_v):\n",
        "    return int(v * max_v / PARAMETER_MAX)\n",
        "\n",
        "\n",
        "def fixmatch_augment_pool():\n",
        "    # FixMatch paper\n",
        "    augs = [(AutoContrast, None, None),\n",
        "            (Brightness, 0.9, 0.05),\n",
        "            (Color, 0.9, 0.05),\n",
        "            (Contrast, 0.9, 0.05),\n",
        "            (Equalize, None, None),\n",
        "            (Identity, None, None),\n",
        "            (Posterize, 4, 4),\n",
        "            (Rotate, 30, 0),\n",
        "            (Sharpness, 0.9, 0.05),\n",
        "            (ShearX, 0.3, 0),\n",
        "            (ShearY, 0.3, 0),\n",
        "            (Solarize, 256, 0),\n",
        "            (TranslateX, 0.3, 0),\n",
        "            (TranslateY, 0.3, 0)]\n",
        "    return augs\n",
        "\n",
        "\n",
        "def my_augment_pool():\n",
        "    # Test\n",
        "    augs = [(AutoContrast, None, None),\n",
        "            (Brightness, 1.8, 0.1),\n",
        "            (Color, 1.8, 0.1),\n",
        "            (Contrast, 1.8, 0.1),\n",
        "            (Cutout, 0.2, 0),\n",
        "            (Equalize, None, None),\n",
        "            (Invert, None, None),\n",
        "            (Posterize, 4, 4),\n",
        "            (Rotate, 30, 0),\n",
        "            (Sharpness, 1.8, 0.1),\n",
        "            (ShearX, 0.3, 0),\n",
        "            (ShearY, 0.3, 0),\n",
        "            (Solarize, 256, 0),\n",
        "            (SolarizeAdd, 110, 0),\n",
        "            (TranslateX, 0.45, 0),\n",
        "            (TranslateY, 0.45, 0)]\n",
        "    return augs\n",
        "\n",
        "\n",
        "class RandAugmentPC(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = my_augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            prob = np.random.uniform(0.2, 0.8)\n",
        "            if random.random() + prob >= 1:\n",
        "                img = op(img, v=self.m, max_v=max_v, bias=bias)\n",
        "        img = CutoutAbs(img, int(32*0.5))\n",
        "        return img\n",
        "\n",
        "\n",
        "class RandAugmentMC(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = fixmatch_augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            v = np.random.randint(1, self.m)\n",
        "            if random.random() < 0.5:\n",
        "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
        "        img = CutoutAbs(img, int(32*0.5))\n",
        "        return img"
      ],
      "metadata": {
        "id": "wQfiO49OgoYu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################\n",
        "root = \"./data\"\n",
        "num_labeled = 100\n",
        "#######################\n",
        "\n",
        "transform_labeled = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(size=32,\n",
        "                              padding=int(32*0.125),\n",
        "                              padding_mode='reflect'),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))\n",
        "    ])\n",
        "transform_val = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))\n",
        "    ])\n",
        "\n",
        "class TransformFixMatch(object):\n",
        "    def __init__(self):\n",
        "        self.weak = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(size=32,\n",
        "                                  padding=int(32*0.125),\n",
        "                                  padding_mode='reflect')])\n",
        "        self.strong = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(size=32,\n",
        "                                  padding=int(32*0.125),\n",
        "                                  padding_mode='reflect'),\n",
        "            RandAugmentMC(n=2, m=10)])\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        weak = self.weak(x)\n",
        "        strong = self.strong(x)\n",
        "        return self.normalize(weak), self.normalize(strong)\n",
        "\n",
        "\n",
        "\n",
        "def x_u_split(num_labeled, labels):\n",
        "    num_classes = len(list(set(labels)))\n",
        "    label_per_class = num_labeled // num_classes\n",
        "    labels = np.array(labels)\n",
        "    labeled_idx = []\n",
        "    unlabeled_idx = np.array(range(len(labels)))\n",
        "    for i in range(num_classes):\n",
        "        idx = np.where(labels ==i)[0]\n",
        "        idx = np.random.choice(idx, label_per_class, False)\n",
        "        labeled_idx.extend(idx)\n",
        "    labeled_idx = np.array(labeled_idx)\n",
        "    assert len(labeled_idx) == num_labeled\n",
        "\n",
        "    np.random.shuffle(labeled_idx)\n",
        "    return labeled_idx, unlabeled_idx\n",
        "\n",
        "class CIFAR10SSL(datasets.CIFAR10):\n",
        "    def __init__(self, root, indexs, train=True,\n",
        "                 transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super().__init__(root, train=train,\n",
        "                         transform=transform,\n",
        "                         target_transform=target_transform,\n",
        "                         download=download)\n",
        "        if indexs is not None:\n",
        "            self.data = self.data[indexs]\n",
        "            self.targets = np.array(self.targets)[indexs]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "base_dataset = datasets.CIFAR10(\"./data\", train=True, download=True)\n",
        "num_classes=len(list(set(base_dataset.targets)))\n",
        "\n",
        "train_labeled_idxs, train_unlabeled_idxs = x_u_split(num_labeled, base_dataset.targets) #ラベルがついている画像を指定数準備する\n",
        "\n",
        "train_labeled_dataset = CIFAR10SSL(\n",
        "        root, train_labeled_idxs, train=True,\n",
        "        transform=transform_labeled)\n",
        "\n",
        "train_unlabeled_dataset = CIFAR10SSL(\n",
        "        root, train_unlabeled_idxs, train=True,\n",
        "        transform=TransformFixMatch())\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "        root, train=False, transform=transform_val, download=False)\n",
        "\n",
        "labeled_trainloader = DataLoader(\n",
        "    train_labeled_dataset,\n",
        "    sampler=RandomSampler,\n",
        "    batch_size=8,\n",
        "    num_workers=0,\n",
        "    drop_last=True)\n",
        "\n",
        "unlabeled_trainloader = DataLoader(\n",
        "    train_unlabeled_dataset,\n",
        "    sampler=RandomSampler,\n",
        "    batch_size=32,\n",
        "    num_workers=0,\n",
        "    drop_last=True)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    sampler=SequentialSampler(test_dataset),\n",
        "    batch_size=8,\n",
        "    num_workers=0)\n",
        "\n",
        "\n",
        "print(\"num_classes: \", num_classes)\n",
        "print(\"num_labeled_data: \", len(train_labeled_idxs))\n",
        "print(\"num_unlabeled_data: \", len(train_unlabeled_idxs))\n",
        "print(\"num_test_data: \", len(test_dataset))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "c075f22993b94453a0b208c5205f18f4",
            "d154cda7f9d3478bad3d9853eb35a1c4",
            "388619fa55bd4369bbdea796d2cff352",
            "601bf58ba5ad430aac5ec512e12372cc",
            "8d1114af37714bc1897a9d780c961a43",
            "3d509fd3b1524bda987d276ff498f99d",
            "eeacccfa65ad48db922b10b99c40d150",
            "acc8a6dfa1454c81873b67f8ffe38169",
            "739d1bdfc7454d4ebfe3f08f97b6ab43",
            "17a92cd98ad443948e9929daf10a9098",
            "bd54cd3a67394d90983c2bb5cd8b630d"
          ]
        },
        "id": "IjHaLKJgL5xw",
        "outputId": "701ef324-ef95-482f-9dc6-355f3a73cde1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c075f22993b94453a0b208c5205f18f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "num_classes:  10\n",
            "num_labeled_data:  100\n",
            "num_unlabeled_data:  50000\n",
            "num_test_data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Compose ResNEXT**"
      ],
      "metadata": {
        "id": "mY5hyDi4kpX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mish(x):\n",
        "    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function (https://arxiv.org/abs/1908.08681)\"\"\"\n",
        "    return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "\n",
        "class BatchNorm2d(nn.BatchNorm2d):\n",
        "    \"\"\"How Does BN Increase Collapsed Neural Network Filters? (https://arxiv.org/abs/2001.11216)\"\"\"\n",
        "\n",
        "    def __init__(self, num_features, alpha=0.1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True):\n",
        "        super().__init__(num_features, eps, momentum, affine, track_running_stats)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        return super().forward(x) + self.alpha\n",
        "\n",
        "\n",
        "class ResNeXtBottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride,\n",
        "                 cardinality, base_width, widen_factor):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            in_channels: input channel dimensionality\n",
        "            out_channels: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            cardinality: num of convolution groups.\n",
        "            base_width: base number of channels in each group.\n",
        "            widen_factor: factor to reduce the input dimensionality before convolution.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        width_ratio = out_channels / (widen_factor * 64.)\n",
        "        D = cardinality * int(base_width * width_ratio)\n",
        "        self.conv_reduce = nn.Conv2d(\n",
        "            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_reduce = nn.BatchNorm2d(D, momentum=0.001)\n",
        "        self.conv_conv = nn.Conv2d(D, D,\n",
        "                                   kernel_size=3, stride=stride, padding=1,\n",
        "                                   groups=cardinality, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(D, momentum=0.001)\n",
        "        self.act = mish\n",
        "        self.conv_expand = nn.Conv2d(\n",
        "            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_expand = nn.BatchNorm2d(out_channels, momentum=0.001)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut.add_module('shortcut_conv',\n",
        "                                     nn.Conv2d(in_channels, out_channels,\n",
        "                                               kernel_size=1,\n",
        "                                               stride=stride,\n",
        "                                               padding=0,\n",
        "                                               bias=False))\n",
        "            self.shortcut.add_module(\n",
        "                'shortcut_bn', nn.BatchNorm2d(out_channels, momentum=0.001))\n",
        "\n",
        "    def forward(self, x):\n",
        "        bottleneck = self.conv_reduce.forward(x)\n",
        "        bottleneck = self.act(self.bn_reduce.forward(bottleneck))\n",
        "        bottleneck = self.conv_conv.forward(bottleneck)\n",
        "        bottleneck = self.act(self.bn.forward(bottleneck))\n",
        "        bottleneck = self.conv_expand.forward(bottleneck)\n",
        "        bottleneck = self.bn_expand.forward(bottleneck)\n",
        "        residual = self.shortcut.forward(x)\n",
        "        return self.act(residual + bottleneck)\n",
        "\n",
        "\n",
        "class CifarResNeXt(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNext optimized for the Cifar dataset, as specified in\n",
        "    https://arxiv.org/pdf/1611.05431.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cardinality, depth, num_classes,\n",
        "                 base_width, widen_factor=4):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            cardinality: number of convolution groups.\n",
        "            depth: number of layers.\n",
        "            nlabels: number of classes\n",
        "            base_width: base number of channels in each group.\n",
        "            widen_factor: factor to adjust the channel dimensionality\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.depth = depth\n",
        "        self.block_depth = (self.depth - 2) // 9\n",
        "        self.base_width = base_width\n",
        "        self.widen_factor = widen_factor\n",
        "        self.nlabels = num_classes\n",
        "        self.output_size = 64\n",
        "        self.stages = [64, 64 * self.widen_factor, 128 *\n",
        "                       self.widen_factor, 256 * self.widen_factor]\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.bn_1 = nn.BatchNorm2d(64, momentum=0.001)\n",
        "        self.act = mish\n",
        "        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n",
        "        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n",
        "        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n",
        "        self.classifier = nn.Linear(self.stages[3], num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight,\n",
        "                                        mode='fan_out',\n",
        "                                        nonlinearity='leaky_relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def block(self, name, in_channels, out_channels, pool_stride=2):\n",
        "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
        "        Args:\n",
        "            name: string name of the current block.\n",
        "            in_channels: number of input channels\n",
        "            out_channels: number of output channels\n",
        "            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n",
        "        Returns: a Module consisting of n sequential bottlenecks.\n",
        "        \"\"\"\n",
        "        block = nn.Sequential()\n",
        "        for bottleneck in range(self.block_depth):\n",
        "            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n",
        "            if bottleneck == 0:\n",
        "                block.add_module(name_, ResNeXtBottleneck(in_channels,\n",
        "                                                          out_channels,\n",
        "                                                          pool_stride,\n",
        "                                                          self.cardinality,\n",
        "                                                          self.base_width,\n",
        "                                                          self.widen_factor))\n",
        "            else:\n",
        "                block.add_module(name_,\n",
        "                                 ResNeXtBottleneck(out_channels,\n",
        "                                                   out_channels,\n",
        "                                                   1,\n",
        "                                                   self.cardinality,\n",
        "                                                   self.base_width,\n",
        "                                                   self.widen_factor))\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1_3x3.forward(x)\n",
        "        x = self.act(self.bn_1.forward(x))\n",
        "        x = self.stage_1.forward(x)\n",
        "        x = self.stage_2.forward(x)\n",
        "        x = self.stage_3.forward(x)\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        x = x.view(-1, self.stages[3])\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "def build_resnext(cardinality, depth, width, num_classes):\n",
        "    logger.info(f\"Model: ResNeXt {depth+1}x{width}\")\n",
        "    return CifarResNeXt(cardinality=cardinality,\n",
        "                        depth=depth,\n",
        "                        base_width=width,\n",
        "                        num_classes=num_classes)"
      ],
      "metadata": {
        "id": "0aqpabhJLpp2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, labeled_trainloader, unlabeled_trainloader, test_loader,\n",
        "          model, optimizer, ema_model, scheduler):\n",
        "    if args.amp:\n",
        "        from apex import amp\n",
        "    global best_acc\n",
        "    test_accs = []\n",
        "    end = time.time()\n",
        "\n",
        "    if args.world_size > 1:\n",
        "        labeled_epoch = 0\n",
        "        unlabeled_epoch = 0\n",
        "        labeled_trainloader.sampler.set_epoch(labeled_epoch)\n",
        "        unlabeled_trainloader.sampler.set_epoch(unlabeled_epoch)\n",
        "\n",
        "    labeled_iter = iter(labeled_trainloader)\n",
        "    unlabeled_iter = iter(unlabeled_trainloader)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        losses_x = AverageMeter()\n",
        "        losses_u = AverageMeter()\n",
        "        mask_probs = AverageMeter()\n",
        "        if not args.no_progress:\n",
        "            p_bar = tqdm(range(args.eval_step),\n",
        "                         disable=args.local_rank not in [-1, 0])\n",
        "        for batch_idx in range(args.eval_step):\n",
        "            try:\n",
        "                inputs_x, targets_x = labeled_iter.next()\n",
        "            except:\n",
        "                if args.world_size > 1:\n",
        "                    labeled_epoch += 1\n",
        "                    labeled_trainloader.sampler.set_epoch(labeled_epoch)\n",
        "                labeled_iter = iter(labeled_trainloader)\n",
        "                inputs_x, targets_x = labeled_iter.next()\n",
        "\n",
        "            try:\n",
        "                (inputs_u_w, inputs_u_s), _ = unlabeled_iter.next()\n",
        "            except:\n",
        "                if args.world_size > 1:\n",
        "                    unlabeled_epoch += 1\n",
        "                    unlabeled_trainloader.sampler.set_epoch(unlabeled_epoch)\n",
        "                unlabeled_iter = iter(unlabeled_trainloader)\n",
        "                (inputs_u_w, inputs_u_s), _ = unlabeled_iter.next()\n",
        "\n",
        "            data_time.update(time.time() - end)\n",
        "            batch_size = inputs_x.shape[0]\n",
        "            inputs = interleave(\n",
        "                torch.cat((inputs_x, inputs_u_w, inputs_u_s)), 2*args.mu+1).to(args.device)\n",
        "            targets_x = targets_x.to(args.device)\n",
        "            logits = model(inputs)\n",
        "            logits = de_interleave(logits, 2*args.mu+1)\n",
        "            logits_x = logits[:batch_size]\n",
        "            logits_u_w, logits_u_s = logits[batch_size:].chunk(2)\n",
        "            del logits\n",
        "\n",
        "            Lx = F.cross_entropy(logits_x, targets_x, reduction='mean')\n",
        "\n",
        "            pseudo_label = torch.softmax(logits_u_w.detach()/args.T, dim=-1)\n",
        "            max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
        "            mask = max_probs.ge(args.threshold).float()\n",
        "\n",
        "            Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
        "                                  reduction='none') * mask).mean()\n",
        "\n",
        "            loss = Lx + args.lambda_u * Lu\n",
        "\n",
        "            if args.amp:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            losses.update(loss.item())\n",
        "            losses_x.update(Lx.item())\n",
        "            losses_u.update(Lu.item())\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            if args.use_ema:\n",
        "                ema_model.update(model)\n",
        "            model.zero_grad()\n",
        "\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "            mask_probs.update(mask.mean().item())\n",
        "            if not args.no_progress:\n",
        "                p_bar.set_description(\"Train Epoch: {epoch}/{epochs:4}. Iter: {batch:4}/{iter:4}. LR: {lr:.4f}. Data: {data:.3f}s. Batch: {bt:.3f}s. Loss: {loss:.4f}. Loss_x: {loss_x:.4f}. Loss_u: {loss_u:.4f}. Mask: {mask:.2f}. \".format(\n",
        "                    epoch=epoch + 1,\n",
        "                    epochs=args.epochs,\n",
        "                    batch=batch_idx + 1,\n",
        "                    iter=args.eval_step,\n",
        "                    lr=scheduler.get_last_lr()[0],\n",
        "                    data=data_time.avg,\n",
        "                    bt=batch_time.avg,\n",
        "                    loss=losses.avg,\n",
        "                    loss_x=losses_x.avg,\n",
        "                    loss_u=losses_u.avg,\n",
        "                    mask=mask_probs.avg))\n",
        "                p_bar.update()\n",
        "\n",
        "        if not args.no_progress:\n",
        "            p_bar.close()\n",
        "\n",
        "        if args.use_ema:\n",
        "            test_model = ema_model.ema\n",
        "        else:\n",
        "            test_model = model\n",
        "\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            test_loss, test_acc = test(args, test_loader, test_model, epoch)\n",
        "\n",
        "            args.writer.add_scalar('train/1.train_loss', losses.avg, epoch)\n",
        "            args.writer.add_scalar('train/2.train_loss_x', losses_x.avg, epoch)\n",
        "            args.writer.add_scalar('train/3.train_loss_u', losses_u.avg, epoch)\n",
        "            args.writer.add_scalar('train/4.mask', mask_probs.avg, epoch)\n",
        "            args.writer.add_scalar('test/1.test_acc', test_acc, epoch)\n",
        "            args.writer.add_scalar('test/2.test_loss', test_loss, epoch)\n",
        "\n",
        "            is_best = test_acc > best_acc\n",
        "            best_acc = max(test_acc, best_acc)\n",
        "\n",
        "            model_to_save = model.module if hasattr(model, \"module\") else model\n",
        "            if args.use_ema:\n",
        "                ema_to_save = ema_model.ema.module if hasattr(\n",
        "                    ema_model.ema, \"module\") else ema_model.ema\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model_to_save.state_dict(),\n",
        "                'ema_state_dict': ema_to_save.state_dict() if args.use_ema else None,\n",
        "                'acc': test_acc,\n",
        "                'best_acc': best_acc,\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "            }, is_best, args.out)\n",
        "\n",
        "            test_accs.append(test_acc)\n",
        "            logger.info('Best top-1 acc: {:.2f}'.format(best_acc))\n",
        "            logger.info('Mean top-1 acc: {:.2f}\\n'.format(\n",
        "                np.mean(test_accs[-20:])))\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        args.writer.close()\n",
        "\n",
        "\n",
        "def test(args, test_loader, model, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "    if not args.no_progress:\n",
        "        test_loader = tqdm(test_loader,\n",
        "                           disable=args.local_rank not in [-1, 0])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            data_time.update(time.time() - end)\n",
        "            model.eval()\n",
        "\n",
        "            inputs = inputs.to(args.device)\n",
        "            targets = targets.to(args.device)\n",
        "            outputs = model(inputs)\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "\n",
        "            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
        "            losses.update(loss.item(), inputs.shape[0])\n",
        "            top1.update(prec1.item(), inputs.shape[0])\n",
        "            top5.update(prec5.item(), inputs.shape[0])\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "            if not args.no_progress:\n",
        "                test_loader.set_description(\"Test Iter: {batch:4}/{iter:4}. Data: {data:.3f}s. Batch: {bt:.3f}s. Loss: {loss:.4f}. top1: {top1:.2f}. top5: {top5:.2f}. \".format(\n",
        "                    batch=batch_idx + 1,\n",
        "                    iter=len(test_loader),\n",
        "                    data=data_time.avg,\n",
        "                    bt=batch_time.avg,\n",
        "                    loss=losses.avg,\n",
        "                    top1=top1.avg,\n",
        "                    top5=top5.avg,\n",
        "                ))\n",
        "        if not args.no_progress:\n",
        "            test_loader.close()\n",
        "\n",
        "    logger.info(\"top-1 acc: {:.2f}\".format(top1.avg))\n",
        "    logger.info(\"top-5 acc: {:.2f}\".format(top5.avg))\n",
        "    return losses.avg, top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint, filename='checkpoint.pth.tar'):\n",
        "    filepath = os.path.join(checkpoint, filename)\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint,\n",
        "                                               'model_best.pth.tar'))\n",
        "def get_cosine_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps,\n",
        "                                    num_training_steps,\n",
        "                                    num_cycles=7./16.,\n",
        "                                    last_epoch=-1):\n",
        "    def _lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        no_progress = float(current_step - num_warmup_steps) / \\\n",
        "            float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
        "\n",
        "    return LambdaLR(optimizer, _lr_lambda, last_epoch)\n",
        "\n",
        "\n",
        "def interleave(x, size):\n",
        "    s = list(x.shape)\n",
        "    return x.reshape([-1, size] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])\n",
        "\n",
        "\n",
        "def de_interleave(x, size):\n",
        "    s = list(x.shape)\n",
        "    return x.reshape([size, -1] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    logger.info('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:, i, :, :].mean()\n",
        "            std[i] += inputs[:, i, :, :].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "H0rc5lW8Cepk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = build_resnext(cardinality=4,\n",
        "                      depth=28,\n",
        "                      width=4,\n",
        "                      num_classes=len(list(set(base_dataset.targets))))\n",
        "\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.1,\n",
        "                          momentum=0.9, nesterov=True)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=2**20)"
      ],
      "metadata": {
        "id": "ybBu0hcXHDnz"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}