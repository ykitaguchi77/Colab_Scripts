{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled97.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyZH5dQIw/ry4dNYzO2fAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Colab_Scripts/blob/master/FixMatch_pytorh_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**FixMatch-pytorch for Colab**\n",
        "This is an unofficial implementation of FixMatch-pytoch for Colab, based on https://github.com/kekmodel/FixMatch-pytorch.\n"
      ],
      "metadata": {
        "id": "n5cGRM7-llul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EtVI0tQ-C9gy"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.ImageDraw\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "best_acc = 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Define RandAugument**"
      ],
      "metadata": {
        "id": "Q6vcOrsfg4_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAMETER_MAX = 10\n",
        "\n",
        "\n",
        "def AutoContrast(img, **kwarg):\n",
        "    return PIL.ImageOps.autocontrast(img)\n",
        "\n",
        "\n",
        "def Brightness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
        "\n",
        "\n",
        "def Color(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
        "\n",
        "\n",
        "def Contrast(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
        "\n",
        "\n",
        "def Cutout(img, v, max_v, bias=0):\n",
        "    if v == 0:\n",
        "        return img\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    v = int(v * min(img.size))\n",
        "    return CutoutAbs(img, v)\n",
        "\n",
        "\n",
        "def CutoutAbs(img, v, **kwarg):\n",
        "    w, h = img.size\n",
        "    x0 = np.random.uniform(0, w)\n",
        "    y0 = np.random.uniform(0, h)\n",
        "    x0 = int(max(0, x0 - v / 2.))\n",
        "    y0 = int(max(0, y0 - v / 2.))\n",
        "    x1 = int(min(w, x0 + v))\n",
        "    y1 = int(min(h, y0 + v))\n",
        "    xy = (x0, y0, x1, y1)\n",
        "    # gray\n",
        "    color = (127, 127, 127)\n",
        "    img = img.copy()\n",
        "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
        "    return img\n",
        "\n",
        "\n",
        "def Equalize(img, **kwarg):\n",
        "    return PIL.ImageOps.equalize(img)\n",
        "\n",
        "\n",
        "def Identity(img, **kwarg):\n",
        "    return img\n",
        "\n",
        "\n",
        "def Invert(img, **kwarg):\n",
        "    return PIL.ImageOps.invert(img)\n",
        "\n",
        "\n",
        "def Posterize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.posterize(img, v)\n",
        "\n",
        "\n",
        "def Rotate(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "\n",
        "def Sharpness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
        "\n",
        "\n",
        "def ShearX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "\n",
        "\n",
        "def ShearY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
        "\n",
        "\n",
        "def Solarize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.solarize(img, 256 - v)\n",
        "\n",
        "\n",
        "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    img_np = np.array(img).astype(np.int)\n",
        "    img_np = img_np + v\n",
        "    img_np = np.clip(img_np, 0, 255)\n",
        "    img_np = img_np.astype(np.uint8)\n",
        "    img = Image.fromarray(img_np)\n",
        "    return PIL.ImageOps.solarize(img, threshold)\n",
        "\n",
        "\n",
        "def TranslateX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[0])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[1])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "\n",
        "def _float_parameter(v, max_v):\n",
        "    return float(v) * max_v / PARAMETER_MAX\n",
        "\n",
        "\n",
        "def _int_parameter(v, max_v):\n",
        "    return int(v * max_v / PARAMETER_MAX)\n",
        "\n",
        "\n",
        "def fixmatch_augment_pool():\n",
        "    # FixMatch paper\n",
        "    augs = [(AutoContrast, None, None),\n",
        "            (Brightness, 0.9, 0.05),\n",
        "            (Color, 0.9, 0.05),\n",
        "            (Contrast, 0.9, 0.05),\n",
        "            (Equalize, None, None),\n",
        "            (Identity, None, None),\n",
        "            (Posterize, 4, 4),\n",
        "            (Rotate, 30, 0),\n",
        "            (Sharpness, 0.9, 0.05),\n",
        "            (ShearX, 0.3, 0),\n",
        "            (ShearY, 0.3, 0),\n",
        "            (Solarize, 256, 0),\n",
        "            (TranslateX, 0.3, 0),\n",
        "            (TranslateY, 0.3, 0)]\n",
        "    return augs\n",
        "\n",
        "\n",
        "def my_augment_pool():\n",
        "    # Test\n",
        "    augs = [(AutoContrast, None, None),\n",
        "            (Brightness, 1.8, 0.1),\n",
        "            (Color, 1.8, 0.1),\n",
        "            (Contrast, 1.8, 0.1),\n",
        "            (Cutout, 0.2, 0),\n",
        "            (Equalize, None, None),\n",
        "            (Invert, None, None),\n",
        "            (Posterize, 4, 4),\n",
        "            (Rotate, 30, 0),\n",
        "            (Sharpness, 1.8, 0.1),\n",
        "            (ShearX, 0.3, 0),\n",
        "            (ShearY, 0.3, 0),\n",
        "            (Solarize, 256, 0),\n",
        "            (SolarizeAdd, 110, 0),\n",
        "            (TranslateX, 0.45, 0),\n",
        "            (TranslateY, 0.45, 0)]\n",
        "    return augs\n",
        "\n",
        "\n",
        "class RandAugmentPC(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = my_augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            prob = np.random.uniform(0.2, 0.8)\n",
        "            if random.random() + prob >= 1:\n",
        "                img = op(img, v=self.m, max_v=max_v, bias=bias)\n",
        "        img = CutoutAbs(img, int(32*0.5))\n",
        "        return img\n",
        "\n",
        "\n",
        "class RandAugmentMC(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = fixmatch_augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            v = np.random.randint(1, self.m)\n",
        "            if random.random() < 0.5:\n",
        "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
        "        img = CutoutAbs(img, int(32*0.5))\n",
        "        return img"
      ],
      "metadata": {
        "id": "wQfiO49OgoYu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################\n",
        "root = \"./data\"\n",
        "num_labeled = 100\n",
        "#######################\n",
        "\n",
        "transform_labeled = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(size=32,\n",
        "                              padding=int(32*0.125),\n",
        "                              padding_mode='reflect'),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))\n",
        "    ])\n",
        "transform_val = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))\n",
        "    ])\n",
        "\n",
        "class TransformFixMatch(object):\n",
        "    def __init__(self):\n",
        "        self.weak = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(size=32,\n",
        "                                  padding=int(32*0.125),\n",
        "                                  padding_mode='reflect')])\n",
        "        self.strong = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(size=32,\n",
        "                                  padding=int(32*0.125),\n",
        "                                  padding_mode='reflect'),\n",
        "            RandAugmentMC(n=2, m=10)])\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        weak = self.weak(x)\n",
        "        strong = self.strong(x)\n",
        "        return self.normalize(weak), self.normalize(strong)\n",
        "\n",
        "\n",
        "\n",
        "def x_u_split(num_labeled, labels):\n",
        "    num_classes = len(list(set(labels)))\n",
        "    label_per_class = num_labeled // num_classes\n",
        "    labels = np.array(labels)\n",
        "    labeled_idx = []\n",
        "    unlabeled_idx = np.array(range(len(labels)))\n",
        "    for i in range(num_classes):\n",
        "        idx = np.where(labels ==i)[0]\n",
        "        idx = np.random.choice(idx, label_per_class, False)\n",
        "        labeled_idx.extend(idx)\n",
        "    labeled_idx = np.array(labeled_idx)\n",
        "    assert len(labeled_idx) == num_labeled\n",
        "\n",
        "    np.random.shuffle(labeled_idx)\n",
        "    return labeled_idx, unlabeled_idx\n",
        "\n",
        "class CIFAR10SSL(datasets.CIFAR10):\n",
        "    def __init__(self, root, indexs, train=True,\n",
        "                 transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super().__init__(root, train=train,\n",
        "                         transform=transform,\n",
        "                         target_transform=target_transform,\n",
        "                         download=download)\n",
        "        if indexs is not None:\n",
        "            self.data = self.data[indexs]\n",
        "            self.targets = np.array(self.targets)[indexs]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "base_dataset = datasets.CIFAR10(\"./data\", train=True, download=True)\n",
        "num_classes=len(list(set(base_dataset.targets)))\n",
        "\n",
        "train_labeled_idxs, train_unlabeled_idxs = x_u_split(num_labeled, base_dataset.targets) #ラベルがついている画像を指定数準備する\n",
        "\n",
        "train_labeled_dataset = CIFAR10SSL(\n",
        "        root, train_labeled_idxs, train=True,\n",
        "        transform=transform_labeled)\n",
        "\n",
        "train_unlabeled_dataset = CIFAR10SSL(\n",
        "        root, train_unlabeled_idxs, train=True,\n",
        "        transform=TransformFixMatch())\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "        root, train=False, transform=transform_val, download=False)\n",
        "\n",
        "labeled_trainloader = torch.utils.data.DataLoader(\n",
        "    train_labeled_dataset,\n",
        "    sampler=RandomSampler(train_labeled_dataset),\n",
        "    batch_size=8,\n",
        "    num_workers=0,\n",
        "    drop_last=True)\n",
        "\n",
        "unlabeled_trainloader = torch.utils.data.DataLoader(\n",
        "    train_unlabeled_dataset,\n",
        "    sampler=RandomSampler(train_labeled_dataset),\n",
        "    batch_size=32,\n",
        "    num_workers=0,\n",
        "    drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    sampler=SequentialSampler(test_dataset),\n",
        "    batch_size=8,\n",
        "    num_workers=0)\n",
        "\n",
        "\n",
        "print(\"num_classes: \", num_classes)\n",
        "print(\"num_labeled_data: \", len(train_labeled_idxs))\n",
        "print(\"num_unlabeled_data: \", len(train_unlabeled_idxs))\n",
        "print(\"num_test_data: \", len(test_dataset))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjHaLKJgL5xw",
        "outputId": "e8bd2853-8d0c-4c24-9718-5b07ee2361f1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "num_classes:  10\n",
            "num_labeled_data:  100\n",
            "num_unlabeled_data:  50000\n",
            "num_test_data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Compose ResNEXT**"
      ],
      "metadata": {
        "id": "mY5hyDi4kpX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mish(x):\n",
        "    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function (https://arxiv.org/abs/1908.08681)\"\"\"\n",
        "    return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "\n",
        "class BatchNorm2d(nn.BatchNorm2d):\n",
        "    \"\"\"How Does BN Increase Collapsed Neural Network Filters? (https://arxiv.org/abs/2001.11216)\"\"\"\n",
        "\n",
        "    def __init__(self, num_features, alpha=0.1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True):\n",
        "        super().__init__(num_features, eps, momentum, affine, track_running_stats)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        return super().forward(x) + self.alpha\n",
        "\n",
        "\n",
        "class ResNeXtBottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride,\n",
        "                 cardinality, base_width, widen_factor):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            in_channels: input channel dimensionality\n",
        "            out_channels: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            cardinality: num of convolution groups.\n",
        "            base_width: base number of channels in each group.\n",
        "            widen_factor: factor to reduce the input dimensionality before convolution.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        width_ratio = out_channels / (widen_factor * 64.)\n",
        "        D = cardinality * int(base_width * width_ratio)\n",
        "        self.conv_reduce = nn.Conv2d(\n",
        "            in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_reduce = nn.BatchNorm2d(D, momentum=0.001)\n",
        "        self.conv_conv = nn.Conv2d(D, D,\n",
        "                                   kernel_size=3, stride=stride, padding=1,\n",
        "                                   groups=cardinality, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(D, momentum=0.001)\n",
        "        self.act = mish\n",
        "        self.conv_expand = nn.Conv2d(\n",
        "            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_expand = nn.BatchNorm2d(out_channels, momentum=0.001)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut.add_module('shortcut_conv',\n",
        "                                     nn.Conv2d(in_channels, out_channels,\n",
        "                                               kernel_size=1,\n",
        "                                               stride=stride,\n",
        "                                               padding=0,\n",
        "                                               bias=False))\n",
        "            self.shortcut.add_module(\n",
        "                'shortcut_bn', nn.BatchNorm2d(out_channels, momentum=0.001))\n",
        "\n",
        "    def forward(self, x):\n",
        "        bottleneck = self.conv_reduce.forward(x)\n",
        "        bottleneck = self.act(self.bn_reduce.forward(bottleneck))\n",
        "        bottleneck = self.conv_conv.forward(bottleneck)\n",
        "        bottleneck = self.act(self.bn.forward(bottleneck))\n",
        "        bottleneck = self.conv_expand.forward(bottleneck)\n",
        "        bottleneck = self.bn_expand.forward(bottleneck)\n",
        "        residual = self.shortcut.forward(x)\n",
        "        return self.act(residual + bottleneck)\n",
        "\n",
        "\n",
        "class CifarResNeXt(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNext optimized for the Cifar dataset, as specified in\n",
        "    https://arxiv.org/pdf/1611.05431.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cardinality, depth, num_classes,\n",
        "                 base_width, widen_factor=4):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            cardinality: number of convolution groups.\n",
        "            depth: number of layers.\n",
        "            nlabels: number of classes\n",
        "            base_width: base number of channels in each group.\n",
        "            widen_factor: factor to adjust the channel dimensionality\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.depth = depth\n",
        "        self.block_depth = (self.depth - 2) // 9\n",
        "        self.base_width = base_width\n",
        "        self.widen_factor = widen_factor\n",
        "        self.nlabels = num_classes\n",
        "        self.output_size = 64\n",
        "        self.stages = [64, 64 * self.widen_factor, 128 *\n",
        "                       self.widen_factor, 256 * self.widen_factor]\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.bn_1 = nn.BatchNorm2d(64, momentum=0.001)\n",
        "        self.act = mish\n",
        "        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n",
        "        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n",
        "        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n",
        "        self.classifier = nn.Linear(self.stages[3], num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight,\n",
        "                                        mode='fan_out',\n",
        "                                        nonlinearity='leaky_relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def block(self, name, in_channels, out_channels, pool_stride=2):\n",
        "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
        "        Args:\n",
        "            name: string name of the current block.\n",
        "            in_channels: number of input channels\n",
        "            out_channels: number of output channels\n",
        "            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n",
        "        Returns: a Module consisting of n sequential bottlenecks.\n",
        "        \"\"\"\n",
        "        block = nn.Sequential()\n",
        "        for bottleneck in range(self.block_depth):\n",
        "            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n",
        "            if bottleneck == 0:\n",
        "                block.add_module(name_, ResNeXtBottleneck(in_channels,\n",
        "                                                          out_channels,\n",
        "                                                          pool_stride,\n",
        "                                                          self.cardinality,\n",
        "                                                          self.base_width,\n",
        "                                                          self.widen_factor))\n",
        "            else:\n",
        "                block.add_module(name_,\n",
        "                                 ResNeXtBottleneck(out_channels,\n",
        "                                                   out_channels,\n",
        "                                                   1,\n",
        "                                                   self.cardinality,\n",
        "                                                   self.base_width,\n",
        "                                                   self.widen_factor))\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1_3x3.forward(x)\n",
        "        x = self.act(self.bn_1.forward(x))\n",
        "        x = self.stage_1.forward(x)\n",
        "        x = self.stage_2.forward(x)\n",
        "        x = self.stage_3.forward(x)\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        x = x.view(-1, self.stages[3])\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "def build_resnext(cardinality, depth, width, num_classes):\n",
        "    logger.info(f\"Model: ResNeXt {depth+1}x{width}\")\n",
        "    return CifarResNeXt(cardinality=cardinality,\n",
        "                        depth=depth,\n",
        "                        base_width=width,\n",
        "                        num_classes=num_classes)"
      ],
      "metadata": {
        "id": "0aqpabhJLpp2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(labeled_trainloader, unlabeled_trainloader, test_loader,\n",
        "          model, optimizer,scheduler, epochs):\n",
        "  \n",
        "    global best_acc\n",
        "    test_accs = []\n",
        "    end = time.time()\n",
        "\n",
        "    labeled_iter = iter(labeled_trainloader)\n",
        "    unlabeled_iter = iter(unlabeled_trainloader)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(0, epochs):\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        losses_x = AverageMeter()\n",
        "        losses_u = AverageMeter()\n",
        "        mask_probs = AverageMeter()\n",
        "        \n",
        "        for batch_idx in range(1024):  # 1024 -> eval_step\n",
        "            try:\n",
        "                inputs_x, targets_x = labeled_iter.next()\n",
        "            except:\n",
        "                labeled_iter = iter(labeled_trainloader)\n",
        "                inputs_x, targets_x = labeled_iter.next()\n",
        "\n",
        "            try:\n",
        "                (inputs_u_w, inputs_u_s), _ = unlabeled_iter.next()\n",
        "            except:\n",
        "                unlabeled_iter = iter(unlabeled_trainloader)\n",
        "                (inputs_u_w, inputs_u_s), _ = unlabeled_iter.next()\n",
        "\n",
        "            data_time.update(time.time() - end)\n",
        "            batch_size = inputs_x.shape[0]\n",
        "            inputs = interleave(\n",
        "                torch.cat((inputs_x, inputs_u_w, inputs_u_s)), 2*7+1).to(device) # 7: coefficient of unlabeled batch size\n",
        "            targets_x = targets_x.to(device)\n",
        "            logits = model(inputs)\n",
        "            logits = de_interleave(logits, 2*7+1) # 7: coefficient of unlabeled batch size\n",
        "            logits_x = logits[:batch_size]\n",
        "            logits_u_w, logits_u_s = logits[batch_size:].chunk(2)\n",
        "            del logits\n",
        "\n",
        "            Lx = F.cross_entropy(logits_x, targets_x, reduction='mean')\n",
        "\n",
        "            pseudo_label = torch.softmax(logits_u_w.detach()/1, dim=-1) # 1 -> pseudo label temperature\n",
        "            max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
        "            mask = max_probs.ge(0.95).float() # 0.95 --> threshold\n",
        "\n",
        "            Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
        "                                  reduction='none') * mask).mean()\n",
        "\n",
        "            loss = Lx + 1 * Lu  # 1 -> coefficient of unlabeled loss\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            losses.update(loss.item())\n",
        "            losses_x.update(Lx.item())\n",
        "            losses_u.update(Lu.item())\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "            mask_probs.update(mask.mean().item())\n",
        "\n",
        "            test_model = model\n",
        "\n",
        "\n",
        "def test(test_loader, model, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            data_time.update(time.time() - end)\n",
        "            model.eval()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "\n",
        "            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
        "            losses.update(loss.item(), inputs.shape[0])\n",
        "            top1.update(prec1.item(), inputs.shape[0])\n",
        "            top5.update(prec5.item(), inputs.shape[0])\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            test_loader.set_description(\"Test Iter: {batch:4}/{iter:4}. Data: {data:.3f}s. Batch: {bt:.3f}s. Loss: {loss:.4f}. top1: {top1:.2f}. top5: {top5:.2f}. \".format(\n",
        "                    batch=batch_idx + 1,\n",
        "                    iter=len(test_loader),\n",
        "                    data=data_time.avg,\n",
        "                    bt=batch_time.avg,\n",
        "                    loss=losses.avg,\n",
        "                    top1=top1.avg,\n",
        "                    top5=top5.avg,\n",
        "                ))\n",
        "            test_loader.close()\n",
        "\n",
        "    logger.info(\"top-1 acc: {:.2f}\".format(top1.avg))\n",
        "    logger.info(\"top-5 acc: {:.2f}\".format(top5.avg))\n",
        "    return losses.avg, top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint, filename='checkpoint.pth.tar'):\n",
        "    filepath = os.path.join(checkpoint, filename)\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint,\n",
        "                                               'model_best.pth.tar'))\n",
        "def get_cosine_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps,\n",
        "                                    num_training_steps,\n",
        "                                    num_cycles=7./16.,\n",
        "                                    last_epoch=-1):\n",
        "    def _lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        no_progress = float(current_step - num_warmup_steps) / \\\n",
        "            float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
        "\n",
        "    return LambdaLR(optimizer, _lr_lambda, last_epoch)\n",
        "\n",
        "\n",
        "def interleave(x, size):\n",
        "    s = list(x.shape)\n",
        "    return x.reshape([-1, size] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])\n",
        "\n",
        "\n",
        "def de_interleave(x, size):\n",
        "    s = list(x.shape)\n",
        "    return x.reshape([size, -1] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    logger.info('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:, i, :, :].mean()\n",
        "            std[i] += inputs[:, i, :, :].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "H0rc5lW8Cepk"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = build_resnext(cardinality=4,\n",
        "                      depth=28,\n",
        "                      width=4,\n",
        "                      num_classes=len(list(set(base_dataset.targets))))\n",
        "\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.1,\n",
        "                          momentum=0.9, nesterov=True)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=2**20)\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "train(labeled_trainloader, unlabeled_trainloader, test_loader,\n",
        "          model_ft, optimizer, scheduler, epochs)"
      ],
      "metadata": {
        "id": "ybBu0hcXHDnz",
        "outputId": "2c703fca-72be-43be-f6bb-0de46e411677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ab214c92bc72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m train(labeled_trainloader, unlabeled_trainloader, test_loader,\n\u001b[0;32m---> 15\u001b[0;31m           model_ft, optimizer, scheduler, epochs)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-156c43eef105>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_trainloader, unlabeled_trainloader, test_loader, model, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             inputs = interleave(\n\u001b[0;32m---> 36\u001b[0;31m                 torch.cat((inputs_x, inputs_u_w, inputs_u_s)), 2*7+1).to(device) # 7: coefficient of unlabeled batch size\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mtargets_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-156c43eef105>\u001b[0m in \u001b[0;36minterleave\u001b[0;34m(x, size)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 15, 3, 32, 32]' is invalid for input of size 221184"
          ]
        }
      ]
    }
  ]
}